{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 2: Statistical Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To understand what statistical learning is, let's look at an example. We clients would like to know *how to improve sales of a particular product*. Their advertising dataset consists of sales of their product in 200 different markets. Each of these markets have three different media outlets: TV, radio, and newspaper. The data are displayed as follows: \n",
    "\n",
    "![](../images/figure_2.1.png)\n",
    "\n",
    "It is not possible to directly increase the sales of the product. However, the clients can control the advertising expenditure in each of the three media. So, if we can determine that there is an association between advertising and sales, then we can instruct them to adjust advertising budgets, thereby increasing sales. Our goal, therefore, is to develop an accurate model that can be used to predict sales on the basis of the three media budgets. \n",
    "\n",
    "In this case, the advertising budgets are *input variables* while sales is an *output variable*. The inputs are defined by X, the *independent variable* while the output is defined by Y, the *dependent variable*.\n",
    "\n",
    "In the most general form, a given model has a quantitative response Y and p different predictors, X = (X$_1$, X$_2$, ..., X$_p$). So the general form can be written as:\n",
    "\n",
    "\\begin{equation}\n",
    "Y = f(X) + \\epsilon\n",
    "\\end{equation}\n",
    "\n",
    "where f is some fixed but unknown function of Xs and $\\epsilon$ is a random *error term* which is indepedent of X and has mean zero. In this formulation, f represents the *systematic* information that X provides about Y. In essence, statistical learning refers to a set of approaches for estimating f. We now look at some of the key theoretical concepts that arise in estimating f, as well as tools for evaluating the estimates obtained. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two reasons why we wish to estimate f: *prediction* and *inference*. \n",
    "\n",
    "### Prediction\n",
    "\n",
    "In many situations X are readily available but Y cannot easily be obtained. However, the $\\epsilon$ average out to zero. Hence, we can write our generalized equation as follows:\n",
    "\n",
    "\\begin{equation}\n",
    "\\hat{Y} = \\hat{f}(X)\n",
    "\\end{equation}\n",
    "\n",
    "where $\\hat{f}$ represents an estimate of f, and $\\hat{Y}$ represents the resulting prediction for Y. In such cases, we consider $\\hat{f}$ as a *black box* in the sense, we are not concerned about the exact form of $\\hat{f}$ as long as it yields accurate predictions for Y. \n",
    "\n",
    "The accuracy of $\\hat{Y}$ as a prediction of Y depends on two quantities, which we call the *reducible error* and the *irreducible error*. These errors come about because $\\hat{f}$ is not a perfect estimate of f. However, by reducing the *reducible error* we can get really close f. On the other hand, the *irreducible error* is something we do not have any control. No matter what, we cannot reduce that error. We look at both of these errors as follows:\n",
    "\n",
    "\\begin{equation}\n",
    "E(Y - \\hat{Y})^2 = [f(X) - \\hat{f}(X)]^2 + Var(\\epsilon) \n",
    "\\end{equation}\n",
    "\n",
    "where the first term on the right is reducile error and the second is irreducible error. The focus of this book is on techniques for estimating f with the air to minimizing the reducible error. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
